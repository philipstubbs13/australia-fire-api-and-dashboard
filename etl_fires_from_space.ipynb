{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "import os, zipfile\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URI = 'mongodb://localhost:27017/'\n",
    "MONGO_DBNAME = 'australia_fire_db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data/csvs from zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip files in Resources folder.\n",
    "extension = \".zip\"\n",
    "extracted_dir_name = \".\"\n",
    "\n",
    "# Get the current working directory.\n",
    "# Need to be in root directory of this project for this to work.\n",
    "cwd_dir_name = os.getcwd()\n",
    "print(f\"The current working directory is {cwd_dir_name}.\")\n",
    "\n",
    "os.chdir(\"Resources\") # change directory from working dir to dir with zip file.\n",
    "# This should be the \"Resources folder.\n",
    "dir_name = os.getcwd()\n",
    "print(f\"You are now in the following directory: {dir_name}.\")\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through the items in the directory.\n",
    "    if item.endswith(extension): # check for \".zip\" extension\"\n",
    "        try:\n",
    "            file_name = os.path.abspath(item) # get full path of files\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            unzipped_directory = os.path.join(extracted_dir_name) # reference to the directory where the zip files will be extracted.\n",
    "            zip_ref.extractall(unzipped_directory) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            print(f\"Successfully unzipped {item} into the following folder:{dir_name}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error trying to unzip data file(s).\")\n",
    "            print(e)\n",
    "            \n",
    "# Go up one directory into the project root directory.\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "print(os.path.normpath(os.getcwd() + os.sep + os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv files and read into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to csv files.\n",
    "path_to_csvs = os.path.join(\".\", \"Resources\")\n",
    "all_files = glob.glob(os.path.join(path_to_csvs, \"*.csv\"))\n",
    "\n",
    "df_from_each_file = []\n",
    "\n",
    "for f in all_files:\n",
    "    filename = os.path.basename(f)\n",
    "    df = pd.read_csv(f, encoding =\"ISO-8859-1\")\n",
    "    df_from_each_file.append(df)\n",
    "\n",
    "# Concantenated dataframe\n",
    "concatenated_df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneccessary columns\n",
    "del concatenated_df[\"confidence\"]\n",
    "del concatenated_df[\"scan\"]\n",
    "del concatenated_df[\"track\"]\n",
    "del concatenated_df[\"version\"]\n",
    "del concatenated_df[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for MODIS fires\n",
    "modis_df = concatenated_df.loc[concatenated_df[\"instrument\"] == \"MODIS\"]\n",
    "\n",
    "modis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary columns from modis df.\n",
    "del modis_df[\"bright_ti4\"]\n",
    "del modis_df[\"bright_ti5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for VIIRS fires.\n",
    "viirs_df = concatenated_df.loc[concatenated_df[\"instrument\"] == \"VIIRS\"]\n",
    "\n",
    "viirs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary columns from viirs df.\n",
    "del viirs_df[\"bright_t31\"]\n",
    "del viirs_df[\"brightness\"]\n",
    "del viirs_df[\"daynight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viirs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify counts\n",
    "print(modis_df.count())\n",
    "print(viirs_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nas/null values (if any).\n",
    "modis_df = modis_df.dropna(how=\"any\")\n",
    "viirs_df = viirs_df.dropna(how=\"any\")\n",
    "\n",
    "print(modis_df.count())\n",
    "print(viirs_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(modis_df.dtypes)\n",
    "print(viirs_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df to dict.\n",
    "fires_modis_dict = modis_df.to_dict('range')\n",
    "fires_viirs_dict = viirs_df.to_dict('range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_modis_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_viirs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGO_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client[MONGO_DBNAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_collection = db.fires_modis\n",
    "viirs_collection = db.fires_viirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For testing purposes - load 100 documents into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_into_db(documents, collection):\n",
    "\n",
    "    # Loop through the list of fires and insert into database in chunks.\n",
    "    print(\"Beginning load into database.\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    count = 0\n",
    "    set = 1\n",
    "    for idx, fire in enumerate(documents):\n",
    "        count = count + 1\n",
    "        if count == 101:\n",
    "            break\n",
    "            count = 1\n",
    "            set = set + 1\n",
    "            time.sleep(5)\n",
    "        print(f\"Processing Record {count} of Set {set}\")\n",
    "        try:\n",
    "            collection.insert_one(fire)\n",
    "        except:\n",
    "            print(\"Unable to insert fire data into database. Skipping...\")\n",
    "\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(\"Loading data into database is complete\")\n",
    "    print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_documents_into_db(fires_modis_dict, modis_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_documents_into_db(fires_viirs_dict, viirs_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
